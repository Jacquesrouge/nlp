{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from operator import itemgetter\n",
    "import time\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import random as rd\n",
    "import string\n",
    "from typing import List\n",
    "import unicodedata\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 3])\n"
     ]
    }
   ],
   "source": [
    "PAD_IX = 0\n",
    "EOS_IX = 1\n",
    " \n",
    "LETTRES = string.ascii_letters + string.punctuation + string.digits + ' '\n",
    "id2lettre = dict(zip(range(2, len(LETTRES)+2), LETTRES))\n",
    "id2lettre[PAD_IX] = '' ##NULL CHARACTER\n",
    "id2lettre[EOS_IX] = '|'\n",
    "lettre2id = dict(zip(id2lettre.values(),id2lettre.keys()))\n",
    "\n",
    "ALPHABET_SIZE = len(LETTRES) + 2\n",
    " \n",
    " \n",
    "def normalize(s):\n",
    "    \"\"\" enlève les accents et les majuscules \"\"\"\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if  c in LETTRES)\n",
    " \n",
    " \n",
    "def string2code(s):\n",
    "    \"\"\"prend une séquence de lettres et renvoie la séquence d'entiers correspondantes\"\"\"\n",
    "    return torch.tensor([lettre2id[c] for c in normalize(s)])\n",
    " \n",
    " \n",
    "def code2string(t):\n",
    "    \"\"\" prend une séquence d'entiers et renvoie la séquence de lettres correspondantes \"\"\"\n",
    "    if type(t) != list:\n",
    "        t = t.tolist()\n",
    "    return ''.join(id2lettre[i] for i in t)\n",
    " \n",
    " \n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, text: str, *, maxsent=None, maxlen=None, minlen=1):\n",
    "        # self.text = text\n",
    "        self.list_sentence = [sentence.strip() for sentence in text.split(\".\") if len(sentence) >= minlen]\n",
    "        self.maxlen = maxlen\n",
    "        self.maxsent = maxsent\n",
    " \n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the number of sentences in the dataset.\"\"\"\n",
    "        return len(self.list_sentence)\n",
    " \n",
    "    def __getitem__(self, i):\n",
    "        \"\"\"Returns selected sentence with each character coded as an integer.\n",
    " \n",
    "           Calls string2code.\n",
    "           Length limited by self.maxlen.\n",
    "        \"\"\"\n",
    "        return string2code(self.list_sentence[i][:self.maxlen])\n",
    " \n",
    " \n",
    "def collate_fn(samples: List[List[int]]) -> torch.Tensor:\n",
    "    \"\"\"Computes a batch of sentences with paddings and EOS.\n",
    " \n",
    "    Returns size length x size of batch.\n",
    "    \"\"\"\n",
    "    length = max([len(sample) for sample in samples])\n",
    "    # initialize to PAD_IX\n",
    "    batch = torch.full((length + 1, len(samples)), PAD_IX, dtype=int)\n",
    "    for i, sample in enumerate(samples):\n",
    "        sample_len = len(sample)\n",
    "        batch[:sample_len, i] = sample\n",
    "        batch[sample_len, i] = EOS_IX  # add EOS\n",
    "    return batch\n",
    " \n",
    " \n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    test = \"C'est. Un. Test.\"\n",
    "    ds = TextDataset(test)\n",
    "    loader = DataLoader(ds, collate_fn=collate_fn, batch_size=3)\n",
    "    data = next(iter(loader))\n",
    " \n",
    "    # Longueur maximum\n",
    "    print(data.shape)\n",
    "    assert data.shape == (6, 3)  \n",
    " \n",
    "    # e dans les deux cas\n",
    "    assert data[2, 0] == data[1, 2]\n",
    "    # les chaînes sont identiques\n",
    "    assert test == \" \".join([code2string(s).replace(\"|\",\".\") for s in data.t()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([91, 100])\n",
      "It's great to be in a wonderful city, New York|\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "data_brute = open(r\"C:\\Users\\jacqu\\Scolarite\\M2A\\AMAL\\data\\trump_full_speech.txt\", \"r\")\n",
    "s = data_brute.read()\n",
    "s_norm = normalize(s)      \n",
    "dsT = TextDataset(s_norm,maxlen = 90)\n",
    "loader = DataLoader(dsT, collate_fn=collate_fn, batch_size=100)\n",
    "data = next(iter(loader))\n",
    "print(data.shape)\n",
    "print(code2string(data[:,8].tolist()))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN, GRU, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self,dim,latent,output):\n",
    "        super(RNN,self).__init__()\n",
    "        self.emb = torch.nn.Embedding(len(id2lettre),dim) ##embedding\n",
    "        \n",
    "        self.W_in = nn.Linear(dim,latent)\n",
    "        self.W_hidden = nn.Linear(latent,latent)\n",
    "        self.Tanh = nn.Tanh()\n",
    "        \n",
    "        self.decoder = nn.Linear(latent, output)\n",
    "\n",
    "\n",
    "    def one_step(self,x,h):\n",
    "        \n",
    "        return(self.Tanh(self.W_in(x)+self.W_hidden(h)))\n",
    "\n",
    "    def forward(self,x,h):\n",
    "        x = self.emb(x[:-1]) ##Le shift se situe ici pour conserver seq_len\n",
    "        \n",
    "        len = x.size()[0]\n",
    "        hidden = []\n",
    "        for i in range(len):\n",
    "            h = self.one_step(x[i],h)\n",
    "            hidden.append(h)\n",
    "        return(torch.stack(hidden))\n",
    "\n",
    "    def decode(self,h):\n",
    "        return(self.decoder(h))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "class GRU(nn.Module):\n",
    "    def __init__(self, dim_emb, dim_hidden, dim_out):\n",
    "        super(GRU, self).__init__()\n",
    "        self.dim_emb = dim_emb\n",
    "        self.dim_hidden = dim_hidden\n",
    "        self.dim_out = dim_out\n",
    "        \n",
    "        self.emb = torch.nn.Embedding(len(id2lettre),dim_emb)\n",
    "        self.W_z = torch.nn.Linear(dim_emb+dim_hidden,dim_hidden)\n",
    "        self.W_r = torch.nn.Linear(dim_emb+dim_hidden,dim_hidden)\n",
    "        self.W_h = torch.nn.Linear(dim_emb+dim_hidden,dim_hidden)\n",
    "        self.Sigmo = torch.nn.Sigmoid()\n",
    "        self.Tanh = torch.nn.Tanh()\n",
    "        \n",
    "        self.decoder = nn.Linear(dim_hidden,dim_out)\n",
    "        \n",
    "        \n",
    "    def one_step(self,x,h):\n",
    "        \n",
    "        h_x = torch.cat([h,x],dim = 1)\n",
    "        z_t = self.Sigmo(self.W_z(h_x))\n",
    "        r_t = self.Sigmo(self.W_r(h_x))\n",
    "        h_t = (1-z_t) * h + z_t * self.Tanh(self.W_h(torch.cat([r_t*h,x],dim=1)))\n",
    "        return(h_t)\n",
    "    \n",
    "    def forward(self, x, h):\n",
    "        \n",
    "        x = self.emb(x[:-1]) ##comme vu précedemment\n",
    "        \n",
    "        len = x.size()[0]\n",
    "        hidden = []\n",
    "        for i in range(len):\n",
    "            h = self.one_step(x[i],h)\n",
    "            hidden.append(h)\n",
    "        return(torch.stack(hidden))\n",
    "    \n",
    "    def decode(self,h):\n",
    "        return(self.decoder(h))\n",
    "    \n",
    "    \n",
    "## Je n'ai pas compris comment coder les biais, je propose une version sans biais!    \n",
    "class LSTM(nn.Module):  \n",
    "    def __init__(self, dim_emb, dim_hidden, dim_out,n_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.dim_emb = dim_emb\n",
    "        self.dim_hidden = dim_hidden\n",
    "        self.dim_out = dim_out\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.emb = torch.nn.Embedding(len(id2lettre),dim_emb)\n",
    "        \n",
    "        self.W_f = torch.nn.Linear(dim_emb+dim_hidden,dim_hidden)\n",
    "        self.W_i = torch.nn.Linear(dim_emb+dim_hidden,dim_hidden)\n",
    "        self.W_o = torch.nn.Linear(dim_emb+dim_hidden,dim_hidden)\n",
    "        self.W_C = torch.nn.Linear(dim_emb+dim_hidden,dim_hidden)\n",
    "        self.Sigmo = torch.nn.Sigmoid()\n",
    "        self.Tanh = torch.nn.Tanh()\n",
    "    \n",
    "        self.decoder = nn.Linear(dim_hidden,dim_out)\n",
    "        \n",
    "        \n",
    "    def one_step(self,x,h,C):\n",
    "        \n",
    "        h_x = torch.cat([h,x],dim = 1)\n",
    "        f_t = self.Sigmo(self.W_f(h_x))\n",
    "        i_t = self.Sigmo(self.W_i(h_x))\n",
    "        C_t = f_t * C + i_t * self.Tanh(self.W_C(h_x))\n",
    "        o_t = self.Sigmo(self.W_o(h_x))\n",
    "        h_t = o_t * self.Tanh(C_t)\n",
    "        \n",
    "        return(h_t,C_t)\n",
    "    \n",
    "    def forward(self, x, h, C):\n",
    "        \n",
    "        x = self.emb(x[:-1]) \n",
    "        \n",
    "        len = x.size()[0]\n",
    "        hidden = []\n",
    "        for i in range(len):\n",
    "            (h,C) = self.one_step(x[i],h,C)\n",
    "            hidden.append(h)\n",
    "        return(torch.stack(hidden),C)\n",
    "    \n",
    "    def decode(self,h):\n",
    "        return(self.decoder(h))\n",
    "    \n",
    "    \n",
    "    \n",
    "def maskedCrossEntropy(out,target,padcar):\n",
    "    celosses = loss(out,target)\n",
    "    mask = (target != padcar)\n",
    "    prod = (mask * celosses)\n",
    "    celoss = prod.sum() / mask.sum()\n",
    "    return (celoss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbr_epoch = 175\n",
    "batch_size = 100\n",
    "dim_hidden = 120\n",
    "dim_emb = 60\n",
    "dim_out = len(id2lettre)\n",
    "eps = 2e-3\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IX)\n",
    "network1 = RNN(dim_emb, dim_hidden, dim_out).to(device)\n",
    "optim = torch.optim.Adam(params = network1.parameters(), lr = eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3334: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\numpy\\core\\_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 175 epoch in 2.5e+01 minutes.\n"
     ]
    }
   ],
   "source": [
    "l = float('inf')\n",
    "t =  0\n",
    "list_loss,epoch_loss,Big_list_loss = [],[],[]\n",
    "start = time.time()\n",
    "for epoch in range(nbr_epoch):\n",
    "    \n",
    "    Big_list_loss += list_loss\n",
    "    epoch_loss.append(np.mean(list_loss))\n",
    "    list_loss = []\n",
    "    \n",
    "    for batch_ndx, sample in enumerate(loader):\n",
    "        if batch_ndx == 170:\n",
    "            break        \n",
    "        sample = sample.to(device)\n",
    "        target_data = sample[1:].long().flatten()    \n",
    "        \n",
    "        optim.zero_grad()\n",
    "        hidden = torch.zeros((batch_size, dim_hidden))\n",
    "        hidden = hidden.to(device)\n",
    "        hidden = network1.forward(sample,hidden)\n",
    "        out = network1.decode(hidden)\n",
    "\n",
    "        l = criterion(out.view(-1,len(id2lettre)),target_data)\n",
    "        #if batch_ndx % 50 == 0:\n",
    "            #print(l)\n",
    "            \n",
    "        list_loss.append(float(l))\n",
    "        l.backward()\n",
    "        optim.step()\n",
    "    \n",
    "    #print(\"epoch loss is\",np.mean(list_loss) )\n",
    "stop = time.time()\n",
    "print(f\"Done {nbr_epoch} epoch in {(stop-start)/60 :.2} minutes.\")        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "dim_hidden = 120\n",
    "dim_emb = 60\n",
    "dim_out = len(id2lettre)\n",
    "eps = 1.5e-3\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IX)\n",
    "network2 = GRU(dim_emb, dim_hidden, dim_out).to(device)\n",
    "optim = torch.optim.Adam(params = network2.parameters(), lr = eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 175 epoch in 5.7e+01 minutes.\n"
     ]
    }
   ],
   "source": [
    "l = float('inf')\n",
    "t =  0\n",
    "list_loss_gru,epoch_loss_gru,Big_list_loss_gru = [],[],[]\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(nbr_epoch):\n",
    "    \n",
    "    Big_list_loss_gru += list_loss_gru\n",
    "    epoch_loss_gru.append(np.mean(list_loss_gru))\n",
    "    #print(\"epoch loss is\",np.mean(list_loss_gru) )\n",
    "    list_loss_gru = []\n",
    "    \n",
    "    for batch_ndx, sample in enumerate(loader):\n",
    "        if batch_ndx == 170:\n",
    "            break        \n",
    "        sample = sample.to(device)\n",
    "        target_data = sample[1:].long().flatten()    \n",
    "        \n",
    "        optim.zero_grad()\n",
    "        hidden = torch.zeros((batch_size, dim_hidden))\n",
    "        hidden = hidden.to(device)\n",
    "        hidden = network2.forward(sample,hidden)\n",
    "        out = network2.decode(hidden)\n",
    "\n",
    "        l = criterion(out.view(-1,len(id2lettre)),target_data)\n",
    "        #if batch_ndx % 50 == 0:\n",
    "            #print(l)\n",
    "            \n",
    "        list_loss_gru.append(float(l))\n",
    "        l.backward()\n",
    "        optim.step()\n",
    "stop = time.time()\n",
    "print(f\"Done {nbr_epoch} epoch in {(stop-start)/60 :.2} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "dim_hidden = 120\n",
    "dim_emb = 60\n",
    "dim_out = len(id2lettre)\n",
    "n_layers = 20\n",
    "eps = 1.5e-3\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IX)\n",
    "network3 = LSTM(dim_emb, dim_hidden, dim_out,n_layers).to(device)\n",
    "optim = torch.optim.Adam(params = network3.parameters(), lr = eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 175 epoch in 6.5e+01 minutes.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "l = float('inf')\n",
    "t =  0\n",
    "list_loss_LSTM,epoch_loss_LSTM,Big_list_loss_LSTM = [],[],[]\n",
    "\n",
    "for epoch in range(nbr_epoch):\n",
    "    \n",
    "    Big_list_loss_LSTM += list_loss_LSTM\n",
    "    epoch_loss_LSTM.append(np.mean(list_loss_LSTM))\n",
    "    #print(\"epoch loss is\",np.mean(list_loss_LSTM) )\n",
    "    list_loss_LSTM = []\n",
    "    (state_h, state_c) = (torch.zeros(n_layers, 100, dim_hidden).to(device),\n",
    "                torch.zeros(n_layers, 100, dim_hidden).to(device))\n",
    "    \n",
    "    for batch_ndx, sample in enumerate(loader):\n",
    "        if batch_ndx == 170:\n",
    "            break        \n",
    "        sample = sample.to(device)\n",
    "        target_data = sample[1:].long().flatten()\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        \n",
    "        h_state = torch.zeros((batch_size, dim_hidden)).to(device)\n",
    "        \n",
    "        C_state = torch.zeros((batch_size, dim_hidden)).to(device)\n",
    "        \n",
    "        (new_h,new_C) = network3.forward(sample,h_state,C_state)\n",
    "\n",
    "        out = network3.decode(new_h)\n",
    "        \n",
    "        \n",
    "        l = criterion(out.view(-1,len(id2lettre)),target_data)\n",
    "            \n",
    "        list_loss_LSTM.append(float(l))\n",
    "        l.backward()\n",
    "        optim.step()\n",
    "stop = time.time()\n",
    "print(f\"Done {nbr_epoch} epoch in {(stop-start)/60 :.2} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.arange(len(epoch_loss)),epoch_loss,label = 'loss Rnn')\n",
    "ax.plot(np.arange(len(epoch_loss_gru)),epoch_loss_gru,label = 'loss GRU')\n",
    "ax.plot(np.arange(len(epoch_loss_LSTM)),epoch_loss_LSTM,label = 'loss LSTM')\n",
    "ax.set_title(\"Loss amelioration by epoch\")\n",
    "ax.set_xlabel(\"epoch\")\n",
    "ax.set_ylabel(\"SoftMaxLoss\")\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les résultats sont ceux attendus : le LSTM fini par dépasser le GRU, et ils sont tout les deux biens meilleurs qu'un RNN classique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Generation de caractères"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Je vais générer des samples sur les meilleures estimations, les phrases sont \n",
    "#trop aléatoires sinon. C'est le Nucleus sampling.\n",
    "def nucleus_sampler(probs, k):\n",
    "    _, indices = torch.sort(probs)\n",
    "    probs[indices.data[:-k]] = 0\n",
    "    sampled_index = torch.multinomial(probs, 1)\n",
    "    return sampled_index\n",
    "#Le réseau Lstm prenant une entrée différente, je code deux fonctions generate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation par  RNN/GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rnn(rnn, emb, decoder, eos, h, start=\"\", maxlen=200):\n",
    "    c = lettre2id[start]\n",
    "    x = emb(torch.tensor(c).to(device)).view(1,60)\n",
    "    h = h.to(device)\n",
    "    len = 0\n",
    "    text = [c]\n",
    "    while (c != eos and len < maxlen):\n",
    "        h = rnn.one_step(x,h)\n",
    "        d = decoder(h).flatten()\n",
    "        d = d.long()\n",
    "        c = torch.argmax(d)\n",
    "        x = emb(c).view(1,60)\n",
    "        text.append(c.item())\n",
    "        len += 1\n",
    "    return (code2string(text))\n",
    "\n",
    "\n",
    "def generate_rnn_nucl(rnn, emb, decoder, eos, h, start=\"\",n_sample=3, maxlen=200):\n",
    "    c = lettre2id[start]\n",
    "    x = emb(torch.tensor(c).to(device)).view(1,60)\n",
    "    h = h.to(device)\n",
    "    len = 0\n",
    "    text = [c]\n",
    "    while (c != eos and len < maxlen):\n",
    "        h = rnn.one_step(x,h)\n",
    "        d = decoder(h).flatten()\n",
    "        prob = nn.functional.softmax(d, dim=0).data \n",
    "        c = nucleus_sampler(prob,n_sample) ### GROS PROBLEME ICI\n",
    "        x = emb(c).view(1,60)\n",
    "        text.append(c.item())\n",
    "        len += 1\n",
    "    return (code2string(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and it'll be a back|\n",
      "vs\n",
      "and it'll deals|\n",
      "book and saying that we will be a great and deal and saying that we will be a great and deal and saying that we will be a great and deal and saying that we will be a great and deal and saying that we w\n",
      "vs\n",
      "book a commany with the people to some to said that we win the strengtor it|\n",
      "And they're going to be a back|\n",
      "vs\n",
      "A Transing and then we also great press foreign something we're going to said, state of the people that was a governor people, they do the stat|\n",
      "But they say the same country|\n",
      "vs\n",
      "Because the something of a group a get together of the presidence was a life my opporters, then the way, anybody|\n",
      "First and deal and saying that we will be a great and deal and saying that we will be a great and deal and saying that we will be a great and deal and saying that we will be a great and deal and saying\n",
      "vs\n",
      "For people|\n",
      "God been the people and day|\n",
      "vs\n",
      "God But the change and state of the people|\n",
      "manked and deal and saying that we will be a great and deal and saying that we will be a great and deal and saying that we will be a great and deal and saying that we will be a great and deal and sayin\n",
      "vs\n",
      "murting in so state|\n",
      "Donald Trump|\n",
      "vs\n",
      "Dona way to even one in the people what we will said who say to be these care to the world|\n",
      "pooteful the state|\n",
      "vs\n",
      "panitited a disagence were starting that has befions on the wall|\n",
      "date deals|\n",
      "vs\n",
      "dendans|\n",
      "xuse they're going to be a back|\n",
      "vs\n",
      "xant the world who said we don't know what I want to how the country|\n",
      "zenal and saying that we will be a back|\n",
      "vs\n",
      "zens|\n",
      "People who doesn't be a back|\n",
      "vs\n",
      "Pretty our country with the wonderent and shin it|\n",
      "God been the people and day|\n",
      "vs\n",
      "Goting that we will say to be a grow a secrets the sent that tough money|\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hidden = torch.zeros((1, dim_hidden))\n",
    "D = ['a','b','A','B','F','G','m','D','p','d','x','z','P','G']\n",
    "for start in D:\n",
    "    print(generate_rnn(network1,network1.emb,network1.decode,EOS_IX,hidden,start))\n",
    "    print('vs')\n",
    "    print(generate_rnn_nucl(network1,network1.emb,network1.decode,EOS_IX,hidden,start))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and safe again|\n",
      "vs\n",
      "and the most deals and was that's all of the stupid, we're going to st|\n",
      "borth in the corruption is the best in the world|\n",
      "vs\n",
      "burn't thing we're going to have a great time that we have to build a li|\n",
      "And then the miners are going to be a big day|\n",
      "vs\n",
      "And we're going to be a charted incredible|\n",
      "But they're going to be a big back that has been said that it was the money|\n",
      "vs\n",
      "But they're not some policing into offer the same place|\n",
      "First of the most important campaign in the country|\n",
      "vs\n",
      "First of our military is not the state|\n",
      "God bless you|\n",
      "vs\n",
      "Go aheroo foreign policy|\n",
      "mines of illegal immigrants and replace Obamacare|\n",
      "vs\n",
      "my failunder safe again, we are going to stand up to the wall|\n",
      "Donald Trump|\n",
      "vs\n",
      "Donald Trump|\n",
      "phation has been in the world|\n",
      "vs\n",
      "phole day is all of the single life, and the money|\n",
      "d|\n",
      "vs\n",
      "dic|\n",
      "xind of its manufacturing jobs since the benefitary of the |\n",
      "vs\n",
      "xind the same done to believe it|\n",
      "hildaild Donat of my country and the best|\n",
      "vs\n",
      "hater was good foreign countries|\n",
      "People want to be a badly and then she said it and the best|\n",
      "vs\n",
      "People don't local safety to the power were a neard the mission, we will build the problem|\n",
      "God bless you|\n",
      "vs\n",
      "Go out that we're a very saying, and it was thing women|\n"
     ]
    }
   ],
   "source": [
    "hidden = torch.zeros((1, dim_hidden))\n",
    "D = ['a','b','A','B','F','G','m','D','p','d','x','h','P','G']\n",
    "for start in D:\n",
    "    print(generate_rnn(network2,network2.emb,network2.decode,EOS_IX,hidden,start))\n",
    "    print('vs')\n",
    "    print(generate_rnn_nucl(network2,network2.emb,network2.decode,EOS_IX,hidden,start))\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation par LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lstm(rnn, emb, decoder, eos, h,cache, start=\"C\", maxlen=150):\n",
    "    c = lettre2id[start]\n",
    "    x = emb(torch.tensor(c).to(device)).view(1,60)\n",
    "    h = h.to(device)\n",
    "    cache = cache.to(device)\n",
    "    len = 0\n",
    "    text = [c]\n",
    "    while (c != eos and len < maxlen):\n",
    "        h,cache = rnn.one_step(x,h,cache)\n",
    "        d = decoder(h).flatten()\n",
    "        d = d.long()\n",
    "        c = torch.argmax(d)\n",
    "        x = emb(c).view(1,60)\n",
    "        text.append(c.item())\n",
    "        len += 1\n",
    "    return (code2string(text))\n",
    "\n",
    "def generate_lstm_nucl(rnn, emb, decoder, eos, h,cache, start=\"\",n_sample=3, maxlen=150):\n",
    "    c = lettre2id[start]\n",
    "    x = emb(torch.tensor(c).to(device)).view(1,60)\n",
    "    h = h.to(device)\n",
    "    cache = cache.to(device)\n",
    "    len = 0\n",
    "    text = [c]\n",
    "    while (c != eos and len < maxlen):\n",
    "        h,cache = rnn.one_step(x,h,cache)\n",
    "        d = decoder(h).flatten()\n",
    "        prob = nn.functional.softmax(d, dim=0).data \n",
    "        c = nucleus_sampler(prob,n_sample)\n",
    "        x = emb(c).view(1,60)\n",
    "        text.append(c.item())\n",
    "        len += 1\n",
    "    return (code2string(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and more than they do it|\n",
      "vs\n",
      "adiliks and they're going, the people arenal|\n",
      "boly about the beginning of the beginning of the beginning and they have a big deal into the same corrupt personal in the same community and getting ou\n",
      "vs\n",
      "but the president|\n",
      "And it's going to be a states are going to be a states were all the corruption|\n",
      "vs\n",
      "Anybody that saying they'll heavers our jobs|\n",
      "But they're all of the people of the people|\n",
      "vs\n",
      "But to do yesterday support the crowd|\n",
      "For instance|\n",
      "vs\n",
      "Financhisan leaders|\n",
      "God bless you|\n",
      "vs\n",
      "Go amone a share in the polls the middle crime is going to be there for our police|\n",
      "moughed the same corrupt personal in the same community and getting our borders|\n",
      "vs\n",
      "moumbensia four veal people that we're going to bring back off the reason that have been safe|\n",
      "Donald Trump|\n",
      "vs\n",
      "Doesn't they were? Thank you|\n",
      "phoader|\n",
      "vs\n",
      "phisand many others will be about them on a long time|\n",
      "dome had a campaigning|\n",
      "vs\n",
      "do descruping the same people will sent to the people are going in the saming she should have never seen a great country|\n",
      "xecurest goal force|\n",
      "vs\n",
      "xe-millions of more that thinds on the staff and that has the people|\n",
      "My companies will be a states were all the corruption|\n",
      "vs\n",
      "My opponent who have been taken the states in the world|\n",
      "People when she was a really a big deal|\n",
      "vs\n",
      "President Obama is gone for your country|\n",
      "God bless you|\n",
      "vs\n",
      "Getting the speeciet they should be said it out|\n"
     ]
    }
   ],
   "source": [
    "hidden = torch.zeros((1, dim_hidden))\n",
    "cache = torch.zeros((1,dim_hidden))\n",
    "D = ['a','b','A','B','F','G','m','D','p','d','x','M','P','G']\n",
    "for start in D:\n",
    "    print(generate_lstm(network3,network3.emb,network3.decode,EOS_IX,hidden,cache,start))\n",
    "    print('vs')\n",
    "    print(generate_lstm_nucl(network3,network3.emb,network3.decode,EOS_IX,hidden,cache,start))\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Génération de phrases: Beam-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_beam(rnn, emb, decoder, eos, h, k, start=\"\", maxlen=200):\n",
    "    c = lettre2id[start]\n",
    "    x = emb(torch.tensor(c).to(device)).view(1,60)\n",
    "    h = h.to(device)\n",
    "    text = [c]\n",
    "    buffer = [(text, h, 0)]\n",
    "    #eos_code = string2code(eos)\n",
    "    depth = 0\n",
    "    n_eos = int(text[-1] == eos)\n",
    "    while n_eos < len(buffer) and depth < maxlen:\n",
    "        for i, (phrase, h_seq, log_likelihood) in enumerate(buffer):\n",
    "            if phrase[-1] == eos:\n",
    "                buffer[i] = [(phrase, h_seq, 1.05*log_likelihood)]  # it is its own and only child\n",
    "            else:\n",
    "                seq_emb = emb(torch.tensor(phrase[-1]).to(device)).view(1,60)\n",
    "                h = rnn.one_step(seq_emb,h_seq)\n",
    "                output = decoder(h).flatten()\n",
    "                logits = F.log_softmax(output,dim=0)\n",
    "                top_log_prob, top_codes = logits.sort(descending=True)\n",
    "                # Expand parent to children\n",
    "                children=[]\n",
    "                for j in range(k):\n",
    "                    phrase_j = phrase.copy()\n",
    "                    phrase_j.append(top_codes[j].item())\n",
    "                    log_likelihood_j = log_likelihood + top_log_prob[j].item()\n",
    "                    children.append((phrase_j, h, log_likelihood_j))\n",
    "                # Replace parent by children\n",
    "                buffer[i] = children\n",
    "        # Flatten\n",
    "        buffer = list(chain(*buffer))\n",
    "        # Top K\n",
    "        buffer = sorted(buffer, key=itemgetter(2))[-k:]\n",
    "        depth = max(map(lambda x: len(x[0]), buffer))\n",
    "        n_eos = sum([int(phrase[-1] == eos) for phrase, _, _ in buffer])\n",
    "\n",
    "    most_probable_sentence = buffer[0][0]\n",
    "    return code2string(most_probable_sentence)\n",
    "\n",
    "def generate_lstm_beam(rnn, emb, decoder, eos, h_test, c_test, k, start=\"\", maxlen=200):\n",
    "    char = lettre2id[start]\n",
    "    x = emb(torch.tensor(char).to(device)).view(1,60)\n",
    "    h = h_test.to(device)\n",
    "    c = c_test.to(device)\n",
    "    text = [char]\n",
    "    buffer = [(text, h, c, 0)]\n",
    "    #eos_code = string2code(eos)\n",
    "    depth = 0\n",
    "    n_eos = int(text[-1] == eos)\n",
    "    while n_eos < len(buffer) and depth < maxlen:\n",
    "        for i, (phrase, h_seq, c_seq, log_likelihood) in enumerate(buffer):\n",
    "            if phrase[-1] == eos:\n",
    "                buffer[i] = [(phrase, h_seq, c_seq, 1.05*log_likelihood)]  # it is its own and only child\n",
    "            else:\n",
    "                seq_emb = emb(torch.tensor(phrase[-1]).to(device)).view(1,60)\n",
    "                h,c = rnn.one_step(seq_emb,h_seq,c_seq)\n",
    "                output = decoder(h).flatten()\n",
    "                logits = F.log_softmax(output,dim=0)\n",
    "                top_log_prob, top_codes = logits.sort(descending=True)\n",
    "                # Expand parent to children\n",
    "                children=[]\n",
    "                for j in range(k):\n",
    "                    phrase_j = phrase.copy()\n",
    "                    phrase_j.append(top_codes[j].item())\n",
    "                    log_likelihood_j = log_likelihood + top_log_prob[j].item()\n",
    "                    children.append((phrase_j, h, c, log_likelihood_j))\n",
    "                # Replace parent by children\n",
    "                buffer[i] = children\n",
    "        # Flatten\n",
    "        buffer = list(chain(*buffer))\n",
    "        # Top K\n",
    "        buffer = sorted(buffer, key=itemgetter(3))[-k:]\n",
    "        depth = max(map(lambda x: len(x[0]), buffer))\n",
    "        n_eos = sum([int(phrase[-1] == eos) for phrase, _, _, _ in buffer])\n",
    "\n",
    "    phrases = [(code2string(phrase), log_like) for phrase,_,_,log_like in buffer]\n",
    "    most_probable_sentence = buffer[-1][0]\n",
    "    return code2string(most_probable_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donald Trump, they're going to be the most important country and they're going to get the single|\n",
      "Don't believe them to the same people that we're going to have the same going to happen and it's going to be so many others will never believe in the same people that we're going to believe this in th\n"
     ]
    }
   ],
   "source": [
    "start = 'D'\n",
    "hidden = torch.zeros((1,dim_hidden))\n",
    "cache = torch.zeros((1,dim_hidden))\n",
    "print(generate_beam(network2,network2.emb,network2.decode,EOS_IX,hidden,3,start))\n",
    "print(generate_lstm_beam(network3,network3.emb,network3.decode,EOS_IX,hidden,cache,3,start))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
