{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 136521/136521 [00:07<00:00, 18385.65it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 34132/34132 [00:01<00:00, 17069.06it/s]\n"
     ]
    }
   ],
   "source": [
    "# %load C:\\Users\\jacqu\\Scolarite\\M2A\\AMAL\\student_tp6\\src\\tp6-traduction.py\n",
    "import datamaestro\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import logging\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "import unicodedata\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "import time\n",
    "import re\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "FILE = r\"C:\\Users\\jacqu\\Scolarite\\M2A\\AMAL\\data\\en-fra.txt\"\n",
    "\n",
    "#writer = SummaryWriter(\"runs/tag-\"+time.asctime())\n",
    "\n",
    "def normalize(s):\n",
    "    return re.sub(' +',' ', \"\".join(c if c in string.ascii_letters else \" \"\n",
    "         for c in unicodedata.normalize('NFD', s.lower().strip())\n",
    "         if  c in string.ascii_letters+\" \"+string.punctuation)).strip()\n",
    "\n",
    "\n",
    "class Vocabulary:\n",
    "    \"\"\"Permet de gérer un vocabulaire.\n",
    "\n",
    "    En test, il est possible qu'un mot ne soit pas dans le\n",
    "    vocabulaire : dans ce cas le token \"__OOV__\" est utilisé.\n",
    "    Attention : il faut tenir compte de cela lors de l'apprentissage !\n",
    "\n",
    "    Utilisation:\n",
    "\n",
    "    - en train, utiliser v.get(\"blah\", adding=True) pour que le mot soit ajouté\n",
    "      automatiquement\n",
    "    - en test, utiliser v[\"blah\"] pour récupérer l'ID du mot (ou l'ID de OOV)\n",
    "    \"\"\"\n",
    "    PAD = 0\n",
    "    EOS = 1\n",
    "    SOS = 2\n",
    "    OOVID = 3\n",
    "\n",
    "    def __init__(self, oov: bool):\n",
    "        self.oov = oov\n",
    "        self.id2word = [\"PAD\", \"EOS\", \"SOS\"]\n",
    "        self.word2id = {\"PAD\": Vocabulary.PAD, \"EOS\": Vocabulary.EOS, \"SOS\": Vocabulary.SOS}\n",
    "        if oov:\n",
    "            self.word2id[\"__OOV__\"] = Vocabulary.OOVID\n",
    "            self.id2word.append(\"__OOV__\")\n",
    "\n",
    "    def __getitem__(self, word: str):\n",
    "        if self.oov:\n",
    "            return self.word2id.get(word, Vocabulary.OOVID)\n",
    "        return self.word2id[word]\n",
    "\n",
    "    def get(self, word: str, adding=True):\n",
    "        try:\n",
    "            return self.word2id[word]\n",
    "        except KeyError:\n",
    "            if adding:\n",
    "                wordid = len(self.id2word)\n",
    "                self.word2id[word] = wordid\n",
    "                self.id2word.append(word)\n",
    "                return wordid\n",
    "            if self.oov:\n",
    "                return Vocabulary.OOVID\n",
    "            raise\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.id2word)\n",
    "\n",
    "    def getword(self, idx: int):\n",
    "        if idx < len(self):\n",
    "            return self.id2word[idx]\n",
    "        return None\n",
    "\n",
    "    def getwords(self, idx: List[int]):\n",
    "        return [self.getword(i) for i in idx]\n",
    "\n",
    "\n",
    "\n",
    "class TradDataset():\n",
    "    def __init__(self,data,vocOrig,vocDest,adding=True,max_len=10):\n",
    "        self.sentences =[]\n",
    "        for s in tqdm(data.split(\"\\n\")):\n",
    "            if len(s)<1:continue\n",
    "            orig,dest=map(normalize,s.split(\"\\t\")[:2])\n",
    "            if len(orig)>max_len: continue\n",
    "            self.sentences.append((torch.tensor([vocOrig.get(o) for o in orig.split(\" \")]+[Vocabulary.EOS]),torch.tensor([vocDest.get(o) for o in dest.split(\" \")]+[Vocabulary.EOS])))\n",
    "    def __len__(self):return len(self.sentences)\n",
    "    def __getitem__(self,i): return self.sentences[i]\n",
    "\n",
    "\n",
    "\n",
    "def collate(batch):\n",
    "    orig,dest = zip(*batch)\n",
    "    o_len = torch.tensor([len(o) for o in orig])\n",
    "    d_len = torch.tensor([len(d) for d in dest])\n",
    "    return pad_sequence(orig),o_len,pad_sequence(dest),d_len\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "with open(FILE) as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "lines = [lines[x] for x in torch.randperm(len(lines))]\n",
    "idxTrain = int(0.8*len(lines))\n",
    "\n",
    "vocEng = Vocabulary(True)\n",
    "vocFra = Vocabulary(True)\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "MAX_LEN = 200\n",
    "\n",
    "datatrain = TradDataset(\"\".join(lines[:idxTrain]),vocEng,vocFra,max_len=MAX_LEN)\n",
    "datatest = TradDataset(\"\".join(lines[idxTrain:]),vocEng,vocFra,max_len=MAX_LEN)\n",
    "\n",
    "train_loader = DataLoader(datatrain, collate_fn=collate, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(datatest, collate_fn=collate, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "#  TODO:  Implémenter l'encodeur, le décodeur et la boucle d'apprentissage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13787 25684\n"
     ]
    }
   ],
   "source": [
    "print(len(vocEng),len(vocFra))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder/Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, dim_emb, dim_hidden):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.dim_hidden = dim_hidden\n",
    "        self.dim_emb = dim_emb\n",
    "        self.n_layers = 2\n",
    "        self.emb = nn.Embedding(len(vocEng), dim_emb)\n",
    "        self.gru = nn.GRU(dim_emb, dim_hidden,num_layers = self.n_layers)\n",
    "        \n",
    "    def forward(self, x, h):        \n",
    "        z = self.emb(x) \n",
    "        output, h_n = self.gru(z,h)        \n",
    "        return(output,h_n)        \n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return(Variable(next(self.parameters()).data.new(self.n_layers, batch_size, self.dim_hidden)))\n",
    "\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self,dim_emb_fr,dim_hidden):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dim_emb_fr = dim_emb_fr\n",
    "        self.dim_hidden = dim_hidden\n",
    "        \n",
    "        self.emb = nn.Embedding(len(vocFra), dim_emb_fr)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.gru = nn.GRU(dim_emb_eng, dim_hidden,num_layers = 2)\n",
    "        self.decoder = nn.Linear(dim_hidden,len(vocFra))\n",
    "        self.softmax = nn.Softmax(dim=1) ##Check la dim\n",
    "                \n",
    "    def forward(self,x,h):\n",
    "        x_emb_relu = self.relu(self.emb(x))\n",
    "        output,h_n = self.gru(x_emb_relu,h)\n",
    "        return(self.softmax(self.decoder(output)),h_n)\n",
    "   \n",
    "    \n",
    "    \n",
    "    def generate(self, hidden, lenseq=None, SOS_IX = 2, EOS_IX = 1, PAD = 0, random_gen = False):\n",
    "        BATCH_SIZE = hidden.shape[1]\n",
    "        seq = torch.tensor([SOS_IX]).long().repeat(BATCH_SIZE).unsqueeze(0).to(device) #Initialize empty sequence with SOS as first token\n",
    "        seq_probs = torch.tensor([]).to(device)\n",
    "        done_mask = torch.ones(BATCH_SIZE).long().to(device)\n",
    " \n",
    "        while len(seq) <= lenseq and done_mask.sum() > 0:\n",
    "            #encoded_seq, hidden = self.gru(embed_seq, hidden)\n",
    "            #decoded_seq = self.decode(encoded_seq)\n",
    "            decoded_seq, h_n = self.forward(seq,hidden)\n",
    " \n",
    "            if random_gen:\n",
    "                probs = decoded_seq.cpu().numpy()\n",
    "                nxt_wd = np.random.choice(range(len(decoded_seq[-1][0])), p = probs[0])\n",
    "                nxt_wd = torch.tensor(nxt_wd)\n",
    "            else:\n",
    "                nxt_wd = decoded_seq[-1].argmax(dim=1) # Most likely next word\n",
    " \n",
    "            seq = torch.cat((seq, nxt_wd.unsqueeze(0)))\n",
    "            done_mask = done_mask * (seq[-1] != EOS_IX)\n",
    "            seq = seq * done_mask\n",
    "            seq_probs = torch.cat((seq_probs, decoded_seq[-1].unsqueeze(0)))\n",
    " \n",
    "        return seq[1:], seq_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([19, 100, 25684]) torch.Size([19, 100])\n",
      "torch.Size([17, 100, 25684]) torch.Size([17, 100])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 168.00 MiB (GPU 0; 6.00 GiB total capacity; 1.12 GiB already allocated; 95.44 MiB free; 1.81 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-3d47af14cab6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     60\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m         \u001b[0moptim_decod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[0moptim_encod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 168.00 MiB (GPU 0; 6.00 GiB total capacity; 1.12 GiB already allocated; 95.44 MiB free; 1.81 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "# ENCODERS\n",
    " \n",
    "dim_emb, dim_emb_eng = 40,45\n",
    "latent_dim = 70\n",
    "encoder = Encoder(dim_emb, latent_dim).to(device)\n",
    "decoder = Decoder(dim_emb_eng, latent_dim).to(device)\n",
    " \n",
    "# HYPERPARAMETERS\n",
    "\n",
    "n_epoch = 1\n",
    "iter = 0\n",
    "lr = 1e-2\n",
    "constrain_prob = 0.75\n",
    " \n",
    "    \n",
    "# LEARNING\n",
    " \n",
    "PAD = 0\n",
    "optim_encod = torch.optim.Adam(params = encoder.parameters(), lr=lr)\n",
    "optim_decod = torch.optim.Adam(params = decoder.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD)\n",
    " \n",
    "    \n",
    "start = time.time()\n",
    "list_loss,epoch_loss,Big_list_loss = [],[],[]\n",
    "for epoch in range(n_epoch):\n",
    "\n",
    "    Big_list_loss += list_loss\n",
    "    if list_loss != []:\n",
    "        epoch_loss.append(np.mean(list_loss))\n",
    "    list_loss = []\n",
    "    \n",
    "    for eng_seq, len_eng_seq, fr_seq, len_fr_seq in train_loader:\n",
    "        optim_encod.zero_grad()\n",
    "        optim_decod.zero_grad()\n",
    "        eng_seq, fr_seq = eng_seq.to(device), fr_seq.to(device) \n",
    "        hidden_enc = encoder.init_hidden(100).to(device)\n",
    "        encoded_original_seq, hidden = encoder(eng_seq,hidden_enc)\n",
    " \n",
    "        toss = torch.rand(1)\n",
    " \n",
    "        if toss <= constrain_prob:\n",
    "            # TEACHER FORCING\n",
    "            loss = 0\n",
    "            gen_seq_probs = torch.tensor([]).to(device)\n",
    "            for k in range(len(fr_seq)):\n",
    "                nxt_wd, nxt_wd_prob = decoder.generate(hidden, lenseq = 1)\n",
    "                gen_seq_probs = torch.cat((gen_seq_probs, nxt_wd_prob))\n",
    "                _, hidden = decoder(fr_seq[:k+1], hidden)\n",
    "\n",
    "        else:\n",
    "            gen_seq, gen_seq_probs = decoder.generate(hidden, lenseq = len_fr_seq.max())\n",
    "        print(gen_seq_probs.shape,fr_seq.shape)\n",
    "        loss = criterion(gen_seq_probs.view(fr_seq.view(-1).size(0),-1), fr_seq.detach().view(-1))\n",
    "        #print(loss)\n",
    "  \n",
    "        if iter%10 == 0:\n",
    "            #print(f'iter {iter} loss: {loss / len(fr_seq)}')\n",
    "            if iter != 0:\n",
    "                break\n",
    " \n",
    "        loss.backward()\n",
    "        optim_decod.step()\n",
    "        optim_encod.step()\n",
    "        list_loss.append(float(loss))\n",
    "        iter += 1\n",
    "        \n",
    "stop = time.time()\n",
    "print(f\"Done {nbr_epoch} epoch in {(stop-start)/60 :.2} minutes.\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
